{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Aula05.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/gavieira/imersao-dados-2-2020/blob/master/Aula05.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YsiFS5dKtp-0"
      },
      "source": [
        "## Aula 05"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z9XYg7h2FcNq"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import mean_squared_error"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fIwTRps9_ZU6"
      },
      "source": [
        "# No vídeo, usou a url - facilita uso no Colab\n",
        "\n",
        "#fonte = \"https://raw.githubusercontent.com/gavieira/imersao-dados-2-2020/master/MICRODADOS_ENEM_2019_SAMPLE_43278.csv\"\n",
        "#dados = pd.read_csv(fonte)\n",
        "#dados.head()\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UoR8DgbY-U3o"
      },
      "source": [
        "#Setando variáveis\n",
        "\n",
        "# Criadas na aula01\n",
        "dados = pd.read_csv(\"MICRODADOS_ENEM_2019_SAMPLE_43278.csv\")\n",
        "provas = [\"NU_NOTA_CN\",\"NU_NOTA_CH\",\"NU_NOTA_MT\",\"NU_NOTA_LC\",\"NU_NOTA_REDACAO\"]\n",
        "\n",
        "# Criadas na aula 02\n",
        "renda_ordenada = np.sort(dados[\"Q006\"].unique()) \n",
        "dados[\"NU_NOTA_TOTAL\"] = dados[provas].sum(axis=1)\n",
        "provas.append(\"NU_NOTA_TOTAL\")\n",
        "dados_sem_notas_zero = dados.query(\"NU_NOTA_TOTAL != 0\")\n",
        "\n",
        "# Aula 03\n",
        "correlacao = dados_sem_notas_zero[provas].corr()\n",
        "\n",
        "# Aula 04\n",
        "provas_entrada = [\"NU_NOTA_CH\",\"NU_NOTA_LC\", \"NU_NOTA_CN\",\"NU_NOTA_REDACAO\"] # São nossas características, usadas para definir nossa saída\n",
        "prova_saida = \"NU_NOTA_MT\" # È a nota que queremos prever\n",
        "dados_sem_notas_zero = dados_sem_notas_zero[provas].dropna() #Remove os NaN (Not a number) para poder fazer o fit no modelo\n",
        "\n",
        "notas_entrada = x = dados_sem_notas_zero[provas_entrada]\n",
        "notas_saida = y = dados_sem_notas_zero[prova_saida]\n",
        "\n",
        "SEED = 4321 # Poderia ser qqr numero\n",
        "x_treino, x_teste, y_treino, y_teste = train_test_split(x, y, test_size = 0.25,\n",
        "                                                        random_state=SEED)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bAbhPCqYvcxb",
        "outputId": "8f249f60-14e8-408b-e8b3-7f72fa964526",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 87
        }
      },
      "source": [
        "from sklearn.svm import LinearSVR\n",
        "\n",
        "modelo = LinearSVR(random_state=SEED)\n",
        "modelo.fit(x_treino, y_treino)\n",
        "predicoes_matematica = modelo.predict(x_teste)\n",
        "mean_squared_error(y_teste, predicoes_matematica) #mse\n",
        "#Se retirar o parametro random state, o mse muda cada vez que roda\n",
        "#Precisamos retirar a aleatoriedade do modelo tanto quanto possível\n",
        "#E tem modelos que dependem menos do random_state (ex: decision_tree, que só usa aleatoriedade em situações bem específicas)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/home/gabriel/miniconda3/lib/python3.8/site-packages/sklearn/svm/_base.py:976: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  warnings.warn(\"Liblinear failed to converge, increase \"\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "18324.11972400897"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XeS9pHeet7-V",
        "outputId": "da5aa319-5d09-4e3c-c5c5-ca59384e6be3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "from sklearn.tree import DecisionTreeRegressor\n",
        "\n",
        "x_treino, x_teste, y_treino, y_teste = train_test_split(x, y, test_size=0.25) # Para obter sempre o mesmo resultado de predição, basta comentar essa linha\n",
        "modelo_arvore = DecisionTreeRegressor(max_depth = 3) #Não seta o random_state, e sim um parametro chamado max_depth\n",
        "modelo_arvore.fit(x_treino, y_treino)\n",
        "predicoes_matematica_arvore = modelo_arvore.predict(x_teste)\n",
        "mean_squared_error(y_teste, predicoes_matematica_arvore)\n",
        "#Decision_tree possui o parametro random_state na documentação, mas essa aleatoriedade só é usada em situações particulares\n",
        "#Logo, não setamos o random_state, e mesmo assim o resultado é sempre o mesmo toda vez que roda, se dermos o mesmo dataset de treino\n",
        "#Se dermos diferentes x_treino e y_treino, aí sim o resultado muda entre as runs\n",
        "#A aleatoriedade desse e do ultimo modelo não está associado apenas ao random_state, mas tbm à divisão do dataset\n",
        "#Logo, o decisiontree não é isento de aleatoriedade, mas tem um fator de aleatoriedade a mais (random_state)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "5983.264315740933"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 38
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "akPCIb9Ztfvn"
      },
      "source": [
        "**Cross-validation:** Pegar o seu dataset e separar em partes (folds ou quebras). O treino e teste são rodados várias vezes. Em cada run, se usa um fold de teste (e consequentemente de treino) diferente. Logo, os resultados variam e podemos evitar algum bias que estaria presente rodando o treino do modelo várias vezes e obtendo uma média desses treinos.\n",
        "\n",
        "Lembra um pouco o bootstrap (reamostragem).\n",
        "\n",
        "[Link wikipedia](https://en.wikipedia.org/wiki/Cross-validation_(statistics))"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lY8-sJTzvnhT"
      },
      "source": [
        "# Fazendo o cross-validation\n",
        "# A função cross_validate do sklearn usa por padrão o r2 como métrica de scoring. Podemos mudar a métrica com o parametro 'scoring' \n",
        "\n",
        "from sklearn.model_selection import cross_validate\n",
        "\n",
        "modelo_arvore = DecisionTreeRegressor(max_depth=2) # Gera o modelo\n",
        "resultados = cross_validate(modelo_arvore, x, y, cv= 10, scoring=\"neg_mean_squared_error\") #Faz cross-validation com o modelo. Aqui usamos todos os dados (x e y) para os folds. Selecionamos 10 folds (parametro cv)\n",
        "media = (resultados[\"test_score\"]*-1).mean() # Só dá pra multiplicar assim pq é um array, não uma lista\n",
        "\n",
        "# Usa mean_sq_error negativo pq assim quanto maior o valor, melhor. Foi uma escolha de implementação.\n",
        "# E isso é meio que uma guideline de implementação de algoritmos mto comum, onde deve-se prezar por fazer com que quanto maiores os valores, melhores eles são. Isso é importante na otimização de algoritmos\n",
        "# Para além disso, o que está sendo analisado é um score, uma nota (não uma função de erro). Algoritmos geralmente esperam que uma nota siga esse padrão de quanto maior, melhor\n",
        "# Uma coisa é calcular erro, outra coisa é calcular um score (função de erro é diferente de função de score, sendo que a segunda mtas vezes é baseada na primeira)\n",
        "# Podemos converter esses resultados negativos facilmente, multiplicando cada um deles por -1\n",
        "#Por último, podemos obter a média desses resultados para comparar com os diversos modelos. Repare que essa média, baseada em várias iterações de treinamento, possivelmente representa melhor a performance do nosso modelo\n",
        "\n",
        "#OBS: A idéia é que no cross-validation os scores sejam similares. Isso mostra que o modelo se comporta de forma uniforme ao ser treinado com diferentes entradas/grupos de dados.\n",
        "# Se no cross-validation os scores forem muito diferentes, nosso modelo não é 'estável' o bastante e idealmente deve ser substituído por outro (em vez de decision tree, usar lasso, p. ex...)\n",
        "#Logo, é importante obter esses scores e analisar eles: média, max, min, desvio padrão, etc...\n",
        "\n",
        "# Amostragem é importante aqui. Não dá pra fazer cross-validation de forma satisfatória com 2, 3 observações..."
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Nu9AV9e5vvPs",
        "outputId": "482b052a-a802-4e41-f7cd-a9309a214be1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "#Calculando desvio-padrão e o intervalo de confiança\n",
        "\n",
        "from sklearn.model_selection import cross_validate\n",
        "\n",
        "modelo_arvore = DecisionTreeRegressor(max_depth=2)\n",
        "resultados = cross_validate(modelo_arvore, x, y, cv= 10, scoring=\"neg_mean_squared_error\")\n",
        "media = (resultados[\"test_score\"]*-1).mean()\n",
        "desvio_padrao = (resultados[\"test_score\"]*-1).std()\n",
        "#Calculando limites inferior e superior do intervalo de confiança\n",
        "#Da estatística, tem-se que os limites desse intervalo são a média +- 2 * desvio padrão\n",
        "#Ler depois sobre o lance dos 95% e intervalo de confiança\n",
        "\n",
        "lim_inferior = media - (2*desvio_padrao) \n",
        "lim_superior = media + (2*desvio_padrao)\n",
        "\n",
        "print(f\"Intervalo de confiança {lim_inferior} - {lim_superior}\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Intervalo de confiança 6015.722549536811 - 7100.73277978073\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "we1QL6lw2nxd",
        "outputId": "c0122936-cacd-4bc3-a990-2fa4d3535a25",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 67
        }
      },
      "source": [
        "resultados[\"test_score\"]*-1"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([6118.6911947 , 6536.09830186, 6338.64260896, 6456.70685686,\n",
              "       6234.97203593, 6794.25120283, 6713.45694262, 6693.04880297,\n",
              "       6610.58461646, 7085.82408339])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r2HzqJUP6z9B"
      },
      "source": [
        "def calcula_mse(resultados):\n",
        "    media = (resultados[\"test_score\"]*-1).mean()\n",
        "    desvio_padrao = (resultados[\"test_score\"]*-1).std()\n",
        "    lim_inferior = media - (2*desvio_padrao)\n",
        "    lim_superior = media + (2*desvio_padrao)\n",
        "    print(f\"Intervalo de confiança {lim_inferior} - {lim_superior}\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q_mhyKIL7BXO",
        "outputId": "32b6b138-967a-43f7-a4c7-edac2955fd79",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# Cross-validate não tem função de aleatoriedade\n",
        "# Pode replicar bias presentes em folds dos nossos dados e gerar resultados inesperados (ex: dados ordenados)\n",
        "# Mas tem como adicionar um fator de seleção aleatória dos dados que estão nos folds\n",
        "#Ou seja, dar uma embaralhada nos dados - o KFold do sklearn faz isso. Mas isso pode alterar o resultado cada vez que o modelo é rodado\n",
        "\n",
        "#Para obter sempre o mesmo resultado, basta setar o random_state. Dá pra fazer isso com o numpy\n",
        "\n",
        "\n",
        "from sklearn.model_selection import cross_validate\n",
        "from sklearn.model_selection import KFold\n",
        "import numpy as np\n",
        "\n",
        "SEED= 1232\n",
        "np.random.seed(SEED) #Seta o random state para essa célula do notebook\n",
        "\n",
        "\n",
        "partes = KFold(n_splits = 10, shuffle=True)\n",
        "modelo_arvore = DecisionTreeRegressor(max_depth=3)\n",
        "resultados = cross_validate(modelo_arvore, x, y, cv= partes, scoring=\"neg_mean_squared_error\")\n",
        "calcula_mse(resultados)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Intervalo de confiança 5858.741842392759 - 6250.793292491384\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2j5f76kD2v-Q",
        "outputId": "a8ecd2a4-8884-48b6-8181-bcf3ba79b21d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "#Decision Tree: Vai separando os dados e se ramificando. Quanto mais ramos, maior a separação desses dados. Parâmetro max_depth limita isso.\n",
        "#Max depth é um hiperparametro - um parametro cujo valor é usado para controlar o aprendizado da máquina.\n",
        "#Os parametros que setamos ao construir o modelo vazio geralmente são hiperparametros\n",
        "#Logo, esse hiperparametros alteram o resultado\n",
        "\n",
        "#Será que quanto maior a profundidade da árvore, melhor o resultado?\n",
        "#Vamos criar uma função que receba o max_depth como parametro e rode o modelo de árvore com esse valor de max_depth\n",
        "\n",
        "def regressor_arvore(nivel):\n",
        "    SEED= 1232\n",
        "    np.random.seed(SEED)\n",
        "    partes = KFold(n_splits = 10, shuffle=True)\n",
        "    modelo_arvore = DecisionTreeRegressor(max_depth=nivel)\n",
        "    resultados = cross_validate(modelo_arvore, x, y, cv= partes, scoring=\"neg_mean_squared_error\", return_train_score=True) #return_train_score - retorna tanto o score do teste quanto do treino\n",
        "    print(f\"Treino = {(resultados['train_score']*-1).mean()}|Teste = {(resultados['test_score']*-1).mean()}\")\n",
        "\n",
        "regressor_arvore(4)"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Treino = 5760.834451245899|Teste = 5815.707286597402\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zxNNI6py_RlW",
        "outputId": "d3e62201-dd07-437d-8819-ff9d99b9ef4b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 357
        }
      },
      "source": [
        "#Rodando o modelo de árvore para valores cada vez maiores de max_depth\n",
        "#Os resultados do teste melhoram até certo ponto. Depois começam a piorar.\n",
        "#Ou seja, no caso não é verdade que quanto maior o nível melhor o resultado do teste\n",
        "\n",
        "#Agora, o resultado dos dados de treino em si sempre melhoram\n",
        "#O modelo fica tão bom em prever os dados de treino, que ele não performa bem em dados de teste\n",
        "#O modelo fica MTO familiar com os dados de treino, meio que 'decorando' eles. Não consegue extrapolar/generalizar para os dados de teste de forma adequada\n",
        "#No nível 20, o modelo assimilou tanto os dados de treino, que ficou com um certo 'vício' baseado nesses dados.\n",
        "#A esse problema de superajustamento do modelo aos dados de treino é dado o nome \"overfit\"\n",
        "#Problema comum em ML, com diversas soluções\n",
        "# O inverso desse problema ('underfit') também existe\n",
        "#Link - https://towardsdatascience.com/overfitting-vs-underfitting-a-complete-example-d05dd7e19765\n",
        "# https://machinelearningmastery.com/overfitting-and-underfitting-with-machine-learning-algorithms/#:~:text=Overfitting%3A%20Good%20performance%20on%20the,poor%20generalization%20to%20other%20data\n",
        "\n",
        "#Por mais que o depth=8 tenha dado um resultado melhor aqui, isso pode mudar se alterarmos outros parâmetros.\n",
        "#Otimização de modelos de machine learning é um desafio, onde múltiplos (hiper)parametros e suas interações devem ser testados para chegar à melhor predição possível\n",
        "\n",
        "for i in range(1,21):\n",
        "    regressor_arvore(i)"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Treino = 7844.952652412207|Teste = 7857.871770206351\n",
            "Treino = 6527.783475408351|Teste = 6556.886287657656\n",
            "Treino = 6021.275229419075|Teste = 6054.767567442072\n",
            "Treino = 5760.834451245899|Teste = 5815.707286597402\n",
            "Treino = 5598.158955426787|Teste = 5675.196789060744\n",
            "Treino = 5469.677369145869|Teste = 5593.304363812442\n",
            "Treino = 5369.458309852721|Teste = 5541.646599457925\n",
            "Treino = 5276.16965707928|Teste = 5542.053091078966\n",
            "Treino = 5166.713159932668|Teste = 5608.390265709719\n",
            "Treino = 5022.598049115693|Teste = 5761.4934268457555\n",
            "Treino = 4833.560706021637|Teste = 5955.331403579403\n",
            "Treino = 4598.125022484774|Teste = 6217.553668629227\n",
            "Treino = 4316.3791662866815|Teste = 6521.403312280134\n",
            "Treino = 4000.6209880837496|Teste = 6853.984106997142\n",
            "Treino = 3655.8197526274853|Teste = 7224.863053512405\n",
            "Treino = 3295.832684540846|Teste = 7636.168819779455\n",
            "Treino = 2931.7212612043877|Teste = 8071.851486256819\n",
            "Treino = 2575.59534021339|Teste = 8452.126711298857\n",
            "Treino = 2233.574203221172|Teste = 8833.470443567128\n",
            "Treino = 1913.8727239705706|Teste = 9137.12202398264\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O205B_LH6TSS"
      },
      "source": [
        "Desafio 01: Pesquisar sobre intervalo de confiança (Quem quiser discutir no Discord, estaremos lá)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tVXdFdjs_ntc"
      },
      "source": [
        "Muitos vídeos no [youtube](https://www.youtube.com/results?search_query=Confidence+interval). Assistir depois."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dZLl6GHVqCtQ"
      },
      "source": [
        "Desafio 02: Testar com outros parâmetros da árvore de decisão"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "deMzJeggqCtU",
        "outputId": "ed8c8f1b-2939-4d67-c1c4-6ef056e61351",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 170
        }
      },
      "source": [
        "# https://scikit-learn.org/stable/modules/generated/sklearn.tree.DecisionTreeRegressor.html\n",
        "\n",
        "#Testando hiperparametro \"min_samples_split\"\n",
        "\n",
        "def regressor_arvore_split_min(split_min):\n",
        "    SEED= 1232\n",
        "    np.random.seed(SEED)\n",
        "    partes = KFold(n_splits = 10, shuffle=True)\n",
        "    modelo_arvore = DecisionTreeRegressor(min_samples_split=split_min)\n",
        "    resultados = cross_validate(modelo_arvore, x, y, cv= partes, scoring=\"neg_mean_squared_error\", return_train_score=True) #return_train_score - retorna tanto o score do teste quanto do treino\n",
        "    print(f\"Treino = {(resultados['train_score']*-1).mean()}|Teste = {(resultados['test_score']*-1).mean()}\")\n",
        "\n",
        "for i in [x / 10 for x in range(1,10)]:\n",
        "    regressor_arvore_split_min(i)\n",
        "\n",
        "#O resultado piora quando aumentamos o \"min_samples_split\" sem mexer em outros hiperparametros"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Treino = 5984.048414609153|Teste = 6034.479134879735\n",
            "Treino = 6242.3865302606555|Teste = 6278.959617783511\n",
            "Treino = 6979.7598297237255|Teste = 6997.945411211392\n",
            "Treino = 6979.7598297237255|Teste = 6997.945411211392\n",
            "Treino = 7026.380963939734|Teste = 7041.700663450142\n",
            "Treino = 7143.405886727303|Teste = 7156.7069630909655\n",
            "Treino = 7143.405886727303|Teste = 7156.7069630909655\n",
            "Treino = 7844.952652412207|Teste = 7857.871770206351\n",
            "Treino = 7844.952652412207|Teste = 7857.871770206351\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gSilTskZqCtg"
      },
      "source": [
        "Desafio 03: Procurar outras formas de realizar os ajustes de parâmetros com o Sklearn\n",
        "\n",
        "sklearn possui várias funções que basicamente automatizam esse processo de ver a qualidade do modelo com diversos parametros. Aqui usaremos o [GridSearchCV](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.GridSearchCV.html#sklearn.model_selection.GridSearchCV)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dex4zLHWqCtj",
        "outputId": "0d96aaf2-9459-4a8a-8771-ddbab9e45669",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 340
        }
      },
      "source": [
        "# https://scikit-learn.org/stable/modules/grid_search.html\n",
        "\n",
        "#O escolhido foi o GridSearchCV - https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.GridSearchCV.html#sklearn.model_selection.GridSearchCV\n",
        "\n",
        "\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "\n",
        "\n",
        "SEED= 1232\n",
        "np.random.seed(SEED) #Seta o random state para essa célula do notebook\n",
        "\n",
        "parameters = {'max_depth': [x for x in range(1,21)], 'min_samples_split':[x / 10 for x in range(1,10)]}\n",
        "#print(parameters)\n",
        "\n",
        "modelo_arvore = DecisionTreeRegressor()\n",
        "grid = GridSearchCV(modelo_arvore, parameters, scoring=\"neg_mean_squared_error\")\n",
        "grid.fit(x_treino, y_treino)\n"
      ],
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "GridSearchCV(cv=None, error_score=nan,\n",
              "             estimator=DecisionTreeRegressor(ccp_alpha=0.0, criterion='mse',\n",
              "                                             max_depth=None, max_features=None,\n",
              "                                             max_leaf_nodes=None,\n",
              "                                             min_impurity_decrease=0.0,\n",
              "                                             min_impurity_split=None,\n",
              "                                             min_samples_leaf=1,\n",
              "                                             min_samples_split=2,\n",
              "                                             min_weight_fraction_leaf=0.0,\n",
              "                                             presort='deprecated',\n",
              "                                             random_state=None,\n",
              "                                             splitter='best'),\n",
              "             iid='deprecated', n_jobs=None,\n",
              "             param_grid={'max_depth': [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12,\n",
              "                                       13, 14, 15, 16, 17, 18, 19, 20],\n",
              "                         'min_samples_split': [0.1, 0.2, 0.3, 0.4, 0.5, 0.6,\n",
              "                                               0.7, 0.8, 0.9]},\n",
              "             pre_dispatch='2*n_jobs', refit=True, return_train_score=False,\n",
              "             scoring='neg_mean_squared_error', verbose=0)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 40
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "io2r7cqxLPlg",
        "outputId": "dee4c259-6074-4e58-84ca-c8aa3907bc0d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 272
        }
      },
      "source": [
        "#O que o grid nos retorna? Um dicionário\n",
        "sorted(grid.cv_results_.keys())"
      ],
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['mean_fit_time',\n",
              " 'mean_score_time',\n",
              " 'mean_test_score',\n",
              " 'param_max_depth',\n",
              " 'param_min_samples_split',\n",
              " 'params',\n",
              " 'rank_test_score',\n",
              " 'split0_test_score',\n",
              " 'split1_test_score',\n",
              " 'split2_test_score',\n",
              " 'split3_test_score',\n",
              " 'split4_test_score',\n",
              " 'std_fit_time',\n",
              " 'std_score_time',\n",
              " 'std_test_score']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 41
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1bz7h8gqLnEG",
        "outputId": "f1aff5a0-c0f9-422c-a5c5-f90d8e774835",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 782
        }
      },
      "source": [
        "#array with score values\n",
        "grid.cv_results_['mean_test_score']"
      ],
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([-7860.88964172, -7860.88964172, -7860.88964172, -7860.88964172,\n",
              "       -7860.88964172, -7860.88964172, -7860.88964172, -7860.88964172,\n",
              "       -7860.88964172, -6531.00867822, -6531.00867822, -7124.5564794 ,\n",
              "       -7124.5564794 , -7124.5564794 , -7124.5564794 , -7124.5564794 ,\n",
              "       -7860.88964172, -7860.88964172, -6149.67964592, -6306.41933367,\n",
              "       -7007.06049337, -7007.06049337, -7007.06049337, -7124.5564794 ,\n",
              "       -7124.5564794 , -7860.88964172, -7860.88964172, -6041.82473208,\n",
              "       -6266.24790436, -6966.88906407, -6966.88906407, -7007.06049337,\n",
              "       -7124.5564794 , -7124.5564794 , -7860.88964172, -7860.88964172,\n",
              "       -6007.02107991, -6239.55960222, -6966.88906407, -6966.88906407,\n",
              "       -7007.06049337, -7124.5564794 , -7124.5564794 , -7860.88964172,\n",
              "       -7860.88964172, -5995.20035294, -6239.55960222, -6966.88906407,\n",
              "       -6966.88906407, -7007.06049337, -7124.5564794 , -7124.5564794 ,\n",
              "       -7860.88964172, -7860.88964172, -5992.59637127, -6239.55960222,\n",
              "       -6966.88906407, -6966.88906407, -7007.06049337, -7124.5564794 ,\n",
              "       -7124.5564794 , -7860.88964172, -7860.88964172, -5991.26095556,\n",
              "       -6239.55960222, -6966.88906407, -6966.88906407, -7007.06049337,\n",
              "       -7124.5564794 , -7124.5564794 , -7860.88964172, -7860.88964172,\n",
              "       -5991.26095556, -6239.55960222, -6966.88906407, -6966.88906407,\n",
              "       -7007.06049337, -7124.5564794 , -7124.5564794 , -7860.88964172,\n",
              "       -7860.88964172, -5991.26095556, -6239.55960222, -6966.88906407,\n",
              "       -6966.88906407, -7007.06049337, -7124.5564794 , -7124.5564794 ,\n",
              "       -7860.88964172, -7860.88964172, -5991.26095556, -6239.55960222,\n",
              "       -6966.88906407, -6966.88906407, -7007.06049337, -7124.5564794 ,\n",
              "       -7124.5564794 , -7860.88964172, -7860.88964172, -5991.26095556,\n",
              "       -6239.55960222, -6966.88906407, -6966.88906407, -7007.06049337,\n",
              "       -7124.5564794 , -7124.5564794 , -7860.88964172, -7860.88964172,\n",
              "       -5991.26095556, -6239.55960222, -6966.88906407, -6966.88906407,\n",
              "       -7007.06049337, -7124.5564794 , -7124.5564794 , -7860.88964172,\n",
              "       -7860.88964172, -5991.26095556, -6239.55960222, -6966.88906407,\n",
              "       -6966.88906407, -7007.06049337, -7124.5564794 , -7124.5564794 ,\n",
              "       -7860.88964172, -7860.88964172, -5991.26095556, -6239.55960222,\n",
              "       -6966.88906407, -6966.88906407, -7007.06049337, -7124.5564794 ,\n",
              "       -7124.5564794 , -7860.88964172, -7860.88964172, -5991.26095556,\n",
              "       -6239.55960222, -6966.88906407, -6966.88906407, -7007.06049337,\n",
              "       -7124.5564794 , -7124.5564794 , -7860.88964172, -7860.88964172,\n",
              "       -5991.26095556, -6239.55960222, -6966.88906407, -6966.88906407,\n",
              "       -7007.06049337, -7124.5564794 , -7124.5564794 , -7860.88964172,\n",
              "       -7860.88964172, -5991.26095556, -6239.55960222, -6966.88906407,\n",
              "       -6966.88906407, -7007.06049337, -7124.5564794 , -7124.5564794 ,\n",
              "       -7860.88964172, -7860.88964172, -5991.26095556, -6239.55960222,\n",
              "       -6966.88906407, -6966.88906407, -7007.06049337, -7124.5564794 ,\n",
              "       -7124.5564794 , -7860.88964172, -7860.88964172, -5991.26095556,\n",
              "       -6239.55960222, -6966.88906407, -6966.88906407, -7007.06049337,\n",
              "       -7124.5564794 , -7124.5564794 , -7860.88964172, -7860.88964172])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 44
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XiW14IqAMIb8",
        "outputId": "5adb1d57-3f9a-45af-c43e-abf7b043b389",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# Aqui estamos falando do valor de score do teste. Ficou ligeiramente melhor que o que tínhamos\n",
        "grid.best_score_"
      ],
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "-5991.260955559202"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 43
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U10HUqviNOSq",
        "outputId": "064550ba-9294-4094-90d3-8e6ff769a5c6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "#Quais são os valores dos melhores parametros?\n",
        "grid.best_params_\n",
        "\n",
        "#Observe que ao mudar o min_samples_split, o melhor valor de max_depth mudou"
      ],
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'max_depth': 16, 'min_samples_split': 0.1}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 58
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Xo5IKPN_PMDB",
        "outputId": "bd62e65a-fd9a-417c-bb1d-d04ceb40a451",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "#Usando o melhor estimador para predizer\n",
        "grid.best_estimator_.predict(x_teste)"
      ],
      "execution_count": 60,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([644.78144156, 581.26911011, 457.70666667, ..., 581.26911011,\n",
              "       534.76694682, 445.01782488])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 60
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ifY67exPqCtw"
      },
      "source": [
        "Desafio 04: Pesquisar o que é o problema de underfit."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D9bPT9Jj_6z8"
      },
      "source": [
        "Mesma coisa do desafio 01 - vários vídeos no [youtube](https://www.youtube.com/results?search_query=underfit+vs+overfit). Assistir depois"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZCP2APhXqCt8"
      },
      "source": [
        "Desafio 05: Plotar um gráfico com test_score e train_test."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K3B8l1SX_jxU",
        "outputId": "99634270-8e66-4c44-c797-37539211cb5a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 408
        }
      },
      "source": [
        "def regressor_arvore(nivel):\n",
        "    SEED= 1232\n",
        "    np.random.seed(SEED)\n",
        "    partes = KFold(n_splits = 10, shuffle=True)\n",
        "    modelo_arvore = DecisionTreeRegressor(max_depth=nivel)\n",
        "    resultados = cross_validate(modelo_arvore, x, y, cv= partes, scoring=\"neg_mean_squared_error\", return_train_score=True) #return_train_score - retorna tanto o score do teste quanto do treino\n",
        "    return (resultados['train_score']*-1).mean(), (resultados['test_score']*-1).mean()\n",
        "\n",
        "plt.fig\n",
        "\n",
        "for i in range(1,21):\n",
        "  train_sc, teste_sc = regressor_arvore(i)\n",
        "  print(train_sc, teste_sc)\n"
      ],
      "execution_count": 73,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "7844.952652412207 7857.871770206351\n",
            "6527.783475408351 6556.886287657656\n",
            "6021.275229419075 6054.767567442072\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-73-e3bd00eb94ba>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m21\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m   \u001b[0mtrain_sc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mteste_sc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mregressor_arvore\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m   \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_sc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mteste_sc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-73-e3bd00eb94ba>\u001b[0m in \u001b[0;36mregressor_arvore\u001b[0;34m(nivel)\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mpartes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mKFold\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_splits\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mmodelo_arvore\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mDecisionTreeRegressor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmax_depth\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnivel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m     \u001b[0mresultados\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcross_validate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodelo_arvore\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcv\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0mpartes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscoring\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"neg_mean_squared_error\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreturn_train_score\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m#return_train_score - retorna tanto o score do teste quanto do treino\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mresultados\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'train_score'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mresultados\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'test_score'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/sklearn/model_selection/_validation.py\u001b[0m in \u001b[0;36mcross_validate\u001b[0;34m(estimator, X, y, groups, scoring, cv, n_jobs, verbose, fit_params, pre_dispatch, return_train_score, return_estimator, error_score)\u001b[0m\n\u001b[1;32m    234\u001b[0m             \u001b[0mreturn_times\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreturn_estimator\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mreturn_estimator\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    235\u001b[0m             error_score=error_score)\n\u001b[0;32m--> 236\u001b[0;31m         for train, test in cv.split(X, y, groups))\n\u001b[0m\u001b[1;32m    237\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    238\u001b[0m     \u001b[0mzipped_scores\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mscores\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   1030\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_original_iterator\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1031\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1032\u001b[0;31m             \u001b[0;32mwhile\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdispatch_one_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1033\u001b[0m                 \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1034\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/joblib/parallel.py\u001b[0m in \u001b[0;36mdispatch_one_batch\u001b[0;34m(self, iterator)\u001b[0m\n\u001b[1;32m    845\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    846\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 847\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dispatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtasks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    848\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    849\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m_dispatch\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    763\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    764\u001b[0m             \u001b[0mjob_idx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 765\u001b[0;31m             \u001b[0mjob\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_async\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    766\u001b[0m             \u001b[0;31m# A job can complete so quickly than its callback is\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    767\u001b[0m             \u001b[0;31m# called before we get here, causing self._jobs to\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/joblib/_parallel_backends.py\u001b[0m in \u001b[0;36mapply_async\u001b[0;34m(self, func, callback)\u001b[0m\n\u001b[1;32m    206\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mapply_async\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    207\u001b[0m         \u001b[0;34m\"\"\"Schedule a func to be run\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 208\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mImmediateResult\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    209\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    210\u001b[0m             \u001b[0mcallback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/joblib/_parallel_backends.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    570\u001b[0m         \u001b[0;31m# Don't delay the application, to avoid keeping the input\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    571\u001b[0m         \u001b[0;31m# arguments in memory\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 572\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    573\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    574\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    251\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mparallel_backend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_n_jobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    252\u001b[0m             return [func(*args, **kwargs)\n\u001b[0;32m--> 253\u001b[0;31m                     for func, args, kwargs in self.items]\n\u001b[0m\u001b[1;32m    254\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    255\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__reduce__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    251\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mparallel_backend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_n_jobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    252\u001b[0m             return [func(*args, **kwargs)\n\u001b[0;32m--> 253\u001b[0;31m                     for func, args, kwargs in self.items]\n\u001b[0m\u001b[1;32m    254\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    255\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__reduce__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/sklearn/model_selection/_validation.py\u001b[0m in \u001b[0;36m_fit_and_score\u001b[0;34m(estimator, X, y, scorer, train, test, verbose, parameters, fit_params, return_train_score, return_parameters, return_n_test_samples, return_times, return_estimator, error_score)\u001b[0m\n\u001b[1;32m    513\u001b[0m             \u001b[0mestimator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    514\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 515\u001b[0;31m             \u001b[0mestimator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    516\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    517\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/sklearn/tree/_classes.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight, check_input, X_idx_sorted)\u001b[0m\n\u001b[1;32m   1223\u001b[0m             \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1224\u001b[0m             \u001b[0mcheck_input\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcheck_input\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1225\u001b[0;31m             X_idx_sorted=X_idx_sorted)\n\u001b[0m\u001b[1;32m   1226\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1227\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/sklearn/tree/_classes.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight, check_input, X_idx_sorted)\u001b[0m\n\u001b[1;32m    365\u001b[0m                                            min_impurity_split)\n\u001b[1;32m    366\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 367\u001b[0;31m         \u001b[0mbuilder\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuild\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtree_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_idx_sorted\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    368\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    369\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_outputs_\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mis_classifier\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "McOXU98AQu90"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}