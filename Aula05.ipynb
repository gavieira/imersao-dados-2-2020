{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Aula05.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/gavieira/imersao-dados-2-2020/blob/master/Aula05.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YsiFS5dKtp-0"
      },
      "source": [
        "## Aula 05"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z9XYg7h2FcNq"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import mean_squared_error"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fIwTRps9_ZU6"
      },
      "source": [
        "# No vídeo, usou a url - facilita uso no Colab\n",
        "\n",
        "#fonte = \"https://raw.githubusercontent.com/gavieira/imersao-dados-2-2020/master/MICRODADOS_ENEM_2019_SAMPLE_43278.csv\"\n",
        "#dados = pd.read_csv(fonte)\n",
        "#dados.head()\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UoR8DgbY-U3o"
      },
      "source": [
        "#Setando variáveis\n",
        "\n",
        "# Criadas na aula01\n",
        "dados = pd.read_csv(\"MICRODADOS_ENEM_2019_SAMPLE_43278.csv\")\n",
        "provas = [\"NU_NOTA_CN\",\"NU_NOTA_CH\",\"NU_NOTA_MT\",\"NU_NOTA_LC\",\"NU_NOTA_REDACAO\"]\n",
        "\n",
        "# Criadas na aula 02\n",
        "renda_ordenada = np.sort(dados[\"Q006\"].unique()) \n",
        "dados[\"NU_NOTA_TOTAL\"] = dados[provas].sum(axis=1)\n",
        "provas.append(\"NU_NOTA_TOTAL\")\n",
        "dados_sem_notas_zero = dados.query(\"NU_NOTA_TOTAL != 0\")\n",
        "\n",
        "# Aula 03\n",
        "correlacao = dados_sem_notas_zero[provas].corr()\n",
        "\n",
        "# Aula 04\n",
        "provas_entrada = [\"NU_NOTA_CH\",\"NU_NOTA_LC\", \"NU_NOTA_CN\",\"NU_NOTA_REDACAO\"] # São nossas características, usadas para definir nossa saída\n",
        "prova_saida = \"NU_NOTA_MT\" # È a nota que queremos prever\n",
        "dados_sem_notas_zero = dados_sem_notas_zero[provas].dropna() #Remove os NaN (Not a number) para poder fazer o fit no modelo\n",
        "\n",
        "notas_entrada = x = dados_sem_notas_zero[provas_entrada]\n",
        "notas_saida = y = dados_sem_notas_zero[prova_saida]\n",
        "\n",
        "SEED = 4321 # Poderia ser qqr numero\n",
        "x_treino, x_teste, y_treino, y_teste = train_test_split(x, y, test_size = 0.25,\n",
        "                                                        random_state=SEED)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bAbhPCqYvcxb",
        "outputId": "8f249f60-14e8-408b-e8b3-7f72fa964526",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 87
        }
      },
      "source": [
        "from sklearn.svm import LinearSVR\n",
        "\n",
        "modelo = LinearSVR(random_state=SEED)\n",
        "modelo.fit(x_treino, y_treino)\n",
        "predicoes_matematica = modelo.predict(x_teste)\n",
        "mean_squared_error(y_teste, predicoes_matematica) #mse\n",
        "#Se retirar o parametro random state, o mse muda cada vez que roda\n",
        "#Precisamos retirar a aleatoriedade do modelo tanto quanto possível\n",
        "#E tem modelos que dependem menos do random_state (ex: decision_tree, que só usa aleatoriedade em situações bem específicas)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/home/gabriel/miniconda3/lib/python3.8/site-packages/sklearn/svm/_base.py:976: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  warnings.warn(\"Liblinear failed to converge, increase \"\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "18324.11972400897"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XeS9pHeet7-V",
        "outputId": "da5aa319-5d09-4e3c-c5c5-ca59384e6be3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "from sklearn.tree import DecisionTreeRegressor\n",
        "\n",
        "x_treino, x_teste, y_treino, y_teste = train_test_split(x, y, test_size=0.25) # Para obter sempre o mesmo resultado de predição, basta comentar essa linha\n",
        "modelo_arvore = DecisionTreeRegressor(max_depth = 3) #Não seta o random_state, e sim um parametro chamado max_depth\n",
        "modelo_arvore.fit(x_treino, y_treino)\n",
        "predicoes_matematica_arvore = modelo_arvore.predict(x_teste)\n",
        "mean_squared_error(y_teste, predicoes_matematica_arvore)\n",
        "#Decision_tree possui o parametro random_state na documentação, mas essa aleatoriedade só é usada em situações particulares\n",
        "#Logo, não setamos o random_state, e mesmo assim o resultado é sempre o mesmo toda vez que roda, se dermos o mesmo dataset de treino\n",
        "#Se dermos diferentes x_treino e y_treino, aí sim o resultado muda entre as runs\n",
        "#A aleatoriedade desse e do ultimo modelo não está associado apenas ao random_state, mas tbm à divisão do dataset\n",
        "#Logo, o decisiontree não é isento de aleatoriedade, mas tem um fator de aleatoriedade a mais (random_state)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "5983.264315740933"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 38
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "akPCIb9Ztfvn"
      },
      "source": [
        "**Cross-validation:** Pegar o seu dataset e separar em partes (folds ou quebras). O treino e teste são rodados várias vezes. Em cada run, se usa um fold de teste (e consequentemente de treino) diferente. Logo, os resultados variam e podemos evitar algum bias que estaria presente rodando o treino do modelo várias vezes e obtendo uma média desses treinos.\n",
        "\n",
        "Lembra um pouco o bootstrap (reamostragem).\n",
        "\n",
        "[Link wikipedia](https://en.wikipedia.org/wiki/Cross-validation_(statistics))"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lY8-sJTzvnhT"
      },
      "source": [
        "# Fazendo o cross-validation\n",
        "# A função cross_validate do sklearn usa por padrão o r2 como métrica de scoring. Podemos mudar a métrica com o parametro 'scoring' \n",
        "\n",
        "from sklearn.model_selection import cross_validate\n",
        "\n",
        "modelo_arvore = DecisionTreeRegressor(max_depth=2) # Gera o modelo\n",
        "resultados = cross_validate(modelo_arvore, x, y, cv= 10, scoring=\"neg_mean_squared_error\") #Faz cross-validation com o modelo. Aqui usamos todos os dados (x e y) para os folds. Selecionamos 10 folds (parametro cv)\n",
        "media = (resultados[\"test_score\"]*-1).mean() # Só dá pra multiplicar assim pq é um array, não uma lista\n",
        "\n",
        "# Usa mean_sq_error negativo pq assim quanto maior o valor, melhor. Foi uma escolha de implementação.\n",
        "# E isso é meio que uma guideline de implementação de algoritmos mto comum, onde deve-se prezar por fazer com que quanto maiores os valores, melhores eles são. Isso é importante na otimização de algoritmos\n",
        "# Para além disso, o que está sendo analisado é um score, uma nota (não uma função de erro). Algoritmos geralmente esperam que uma nota siga esse padrão de quanto maior, melhor\n",
        "# Uma coisa é calcular erro, outra coisa é calcular um score (função de erro é diferente de função de score, sendo que a segunda mtas vezes é baseada na primeira)\n",
        "# Podemos converter esses resultados negativos facilmente, multiplicando cada um deles por -1\n",
        "#Por último, podemos obter a média desses resultados para comparar com os diversos modelos. Repare que essa média, baseada em várias iterações de treinamento, possivelmente representa melhor a performance do nosso modelo\n",
        "\n",
        "#OBS: A idéia é que no cross-validation os scores sejam similares. Isso mostra que o modelo se comporta de forma uniforme ao ser treinado com diferentes entradas/grupos de dados.\n",
        "# Se no cross-validation os scores forem muito diferentes, nosso modelo não é 'estável' o bastante e idealmente deve ser substituído por outro (em vez de decision tree, usar lasso, p. ex...)\n",
        "#Logo, é importante obter esses scores e analisar eles: média, max, min, desvio padrão, etc...\n",
        "\n",
        "# Amostragem é importante aqui. Não dá pra fazer cross-validation de forma satisfatória com 2, 3 observações..."
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Nu9AV9e5vvPs",
        "outputId": "482b052a-a802-4e41-f7cd-a9309a214be1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "#Calculando desvio-padrão e o intervalo de confiança\n",
        "\n",
        "from sklearn.model_selection import cross_validate\n",
        "\n",
        "modelo_arvore = DecisionTreeRegressor(max_depth=2)\n",
        "resultados = cross_validate(modelo_arvore, x, y, cv= 10, scoring=\"neg_mean_squared_error\")\n",
        "media = (resultados[\"test_score\"]*-1).mean()\n",
        "desvio_padrao = (resultados[\"test_score\"]*-1).std()\n",
        "#Calculando limites inferior e superior do intervalo de confiança\n",
        "#Da estatística, tem-se que os limites desse intervalo são a média +- 2 * desvio padrão\n",
        "#Ler depois sobre o lance dos 95% e intervalo de confiança\n",
        "\n",
        "lim_inferior = media - (2*desvio_padrao) \n",
        "lim_superior = media + (2*desvio_padrao)\n",
        "\n",
        "print(f\"Intervalo de confiança {lim_inferior} - {lim_superior}\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Intervalo de confiança 6015.722549536811 - 7100.73277978073\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "we1QL6lw2nxd",
        "outputId": "c0122936-cacd-4bc3-a990-2fa4d3535a25",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 67
        }
      },
      "source": [
        "resultados[\"test_score\"]*-1"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([6118.6911947 , 6536.09830186, 6338.64260896, 6456.70685686,\n",
              "       6234.97203593, 6794.25120283, 6713.45694262, 6693.04880297,\n",
              "       6610.58461646, 7085.82408339])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r2HzqJUP6z9B"
      },
      "source": [
        "def calcula_mse(resultados):\n",
        "    media = (resultados[\"test_score\"]*-1).mean()\n",
        "    desvio_padrao = (resultados[\"test_score\"]*-1).std()\n",
        "    lim_inferior = media - (2*desvio_padrao)\n",
        "    lim_superior = media + (2*desvio_padrao)\n",
        "    print(f\"Intervalo de confiança {lim_inferior} - {lim_superior}\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q_mhyKIL7BXO",
        "outputId": "32b6b138-967a-43f7-a4c7-edac2955fd79",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# Cross-validate não tem função de aleatoriedade\n",
        "# Pode replicar bias presentes em folds dos nossos dados e gerar resultados inesperados (ex: dados ordenados)\n",
        "# Mas tem como adicionar um fator de seleção aleatória dos dados que estão nos folds\n",
        "#Ou seja, dar uma embaralhada nos dados - o KFold do sklearn faz isso. Mas isso pode alterar o resultado cada vez que o modelo é rodado\n",
        "\n",
        "#Para obter sempre o mesmo resultado, basta setar o random_state. Dá pra fazer isso com o numpy\n",
        "\n",
        "\n",
        "from sklearn.model_selection import cross_validate\n",
        "from sklearn.model_selection import KFold\n",
        "import numpy as np\n",
        "\n",
        "SEED= 1232\n",
        "np.random.seed(SEED) #Seta o random state para essa célula do notebook\n",
        "\n",
        "\n",
        "partes = KFold(n_splits = 10, shuffle=True)\n",
        "modelo_arvore = DecisionTreeRegressor(max_depth=3)\n",
        "resultados = cross_validate(modelo_arvore, x, y, cv= partes, scoring=\"neg_mean_squared_error\")\n",
        "calcula_mse(resultados)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Intervalo de confiança 5858.741842392759 - 6250.793292491384\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2j5f76kD2v-Q",
        "outputId": "a8ecd2a4-8884-48b6-8181-bcf3ba79b21d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "#Decision Tree: Vai separando os dados e se ramificando. Quanto mais ramos, maior a separação desses dados. Parâmetro max_depth limita isso.\n",
        "#Max depth é um hiperparametro - um parametro cujo valor é usado para controlar o aprendizado da máquina.\n",
        "#Os parametros que setamos ao construir o modelo vazio geralmente são hiperparametros\n",
        "#Logo, esse hiperparametros alteram o resultado\n",
        "\n",
        "#Será que quanto maior a profundidade da árvore, melhor o resultado?\n",
        "#Vamos criar uma função que receba o max_depth como parametro e rode o modelo de árvore com esse valor de max_depth\n",
        "\n",
        "def regressor_arvore(nivel):\n",
        "    SEED= 1232\n",
        "    np.random.seed(SEED)\n",
        "    partes = KFold(n_splits = 10, shuffle=True)\n",
        "    modelo_arvore = DecisionTreeRegressor(max_depth=nivel)\n",
        "    resultados = cross_validate(modelo_arvore, x, y, cv= partes, scoring=\"neg_mean_squared_error\", return_train_score=True) #return_train_score - retorna tanto o score do teste quanto do treino\n",
        "    print(f\"Treino = {(resultados['train_score']*-1).mean()}|Teste = {(resultados['test_score']*-1).mean()}\")\n",
        "\n",
        "regressor_arvore(4)"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Treino = 5760.834451245899|Teste = 5815.707286597402\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zxNNI6py_RlW",
        "outputId": "d3e62201-dd07-437d-8819-ff9d99b9ef4b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 357
        }
      },
      "source": [
        "#Rodando o modelo de árvore para valores cada vez maiores de max_depth\n",
        "#Os resultados do teste melhoram até certo ponto. Depois começam a piorar.\n",
        "#Ou seja, no caso não é verdade que quanto maior o nível melhor o resultado do teste\n",
        "\n",
        "#Agora, o resultado dos dados de treino em si sempre melhoram\n",
        "#O modelo fica tão bom em prever os dados de treino, que ele não performa bem em dados de teste\n",
        "#O modelo fica MTO familiar com os dados de treino, meio que 'decorando' eles. Não consegue extrapolar/generalizar para os dados de teste de forma adequada\n",
        "#No nível 20, o modelo assimilou tanto os dados de treino, que ficou com um certo 'vício' baseado nesses dados.\n",
        "#A esse problema de superajustamento do modelo aos dados de treino é dado o nome \"overfit\"\n",
        "#Problema comum em ML, com diversas soluções\n",
        "\n",
        "#Por mais que o depth=8 tenha dado um resultado melhor aqui, isso pode mudar se alterarmos outros parâmetros.\n",
        "#Otimização de modelos de machine learning é um desafio, onde múltiplos (hiper)parametros e suas interações devem ser testados para chegar à melhor predição possível\n",
        "\n",
        "for i in range(1,21):\n",
        "    regressor_arvore(i)"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Treino = 7844.952652412207|Teste = 7857.871770206351\n",
            "Treino = 6527.783475408351|Teste = 6556.886287657656\n",
            "Treino = 6021.275229419075|Teste = 6054.767567442072\n",
            "Treino = 5760.834451245899|Teste = 5815.707286597402\n",
            "Treino = 5598.158955426787|Teste = 5675.196789060744\n",
            "Treino = 5469.677369145869|Teste = 5593.304363812442\n",
            "Treino = 5369.458309852721|Teste = 5541.646599457925\n",
            "Treino = 5276.16965707928|Teste = 5542.053091078966\n",
            "Treino = 5166.713159932668|Teste = 5608.390265709719\n",
            "Treino = 5022.598049115693|Teste = 5761.4934268457555\n",
            "Treino = 4833.560706021637|Teste = 5955.331403579403\n",
            "Treino = 4598.125022484774|Teste = 6217.553668629227\n",
            "Treino = 4316.3791662866815|Teste = 6521.403312280134\n",
            "Treino = 4000.6209880837496|Teste = 6853.984106997142\n",
            "Treino = 3655.8197526274853|Teste = 7224.863053512405\n",
            "Treino = 3295.832684540846|Teste = 7636.168819779455\n",
            "Treino = 2931.7212612043877|Teste = 8071.851486256819\n",
            "Treino = 2575.59534021339|Teste = 8452.126711298857\n",
            "Treino = 2233.574203221172|Teste = 8833.470443567128\n",
            "Treino = 1913.8727239705706|Teste = 9137.12202398264\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O205B_LH6TSS"
      },
      "source": [
        "Desafio 01: Pesquisar sobre intervalo de confiança (Quem quiser discutir no Discord, estaremos lá)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Fq2zfzPIqCtF"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dZLl6GHVqCtQ"
      },
      "source": [
        "Desafio 02: Testar com outros parâmetros da árvore de decisão"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "deMzJeggqCtU"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gSilTskZqCtg"
      },
      "source": [
        "Desafio 03: Procurar outras formas de realizar os ajustes de parâmetros com o Sklearn"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dex4zLHWqCtj"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ifY67exPqCtw"
      },
      "source": [
        "Desafio 04: Pesquisar o que é o problema de underfit."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J1Twqu5iqCtz"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZCP2APhXqCt8"
      },
      "source": [
        "Desafio 05: Plotar um gráfico com test_score e train_test."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K3B8l1SX_jxU"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}